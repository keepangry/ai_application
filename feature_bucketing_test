#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2019/3/15 2:34 PM
# @Author  : yangsen
# @Site    : 
# @File    : task.py
# @Software: PyCharm
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

from sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer, OneHotEncoder
import numpy as np

# cut_pos = [
#     [9.465,10.44,11.22,11.64,12.16,12.67,13.14,13.64,14.11,14.76,15.46,16.65,17.95,19.27,20.57],
#     [13.1,14.23,15.15,15.94,16.85,17.57,18.24,18.9,19.63,20.39,21.35,22.02,23.12,24.8,27.06],
#     [61.06,67.41,71.8,74.68,77.25,79.78,82.69,85.79,88.44,92.87,96.71,103.2,111.8,122.9,133.7],
# ]
cut_pos = [
    [10.44,11.64,12.67,13.64,14.76,16.65,19.27],
    [14.23,15.94,17.57,18.9,20.39,22.02,24.8],
    [67.41,74.68,79.78,85.79,92.87,103.2,122.9],
]


def feature_cut(X):
    global cut_pos
    result = np.zeros(X.shape)
    #
    for row_idx in range(X.shape[0]):
        for col_idx in range(X.shape[1]):
            cuts = cut_pos[col_idx]
            pos = 0
            for cut in cuts:
                if cut > X[row_idx][col_idx]:
                    break
                else:
                    pos += 1
            result[row_idx][col_idx] = pos
    return result


if __name__ == "__main__":
    cancer = load_breast_cancer()
    random_state = 5
    feature_num = 3
    s = 0
    kbin = 0
    cut = 0

    for i in range(10):
        random_state = 100*i+4

        X = cancer.data[:, :feature_num]
        y = cancer.target

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)

        clf = LogisticRegression(random_state=random_state, solver='lbfgs')
        clf.fit(X_train, y_train)
        score = clf.score(X_test, y_test)
        print("before bucketing: %s" % score)
        s += score

        # 等频切分
        kbins = KBinsDiscretizer(n_bins=[9 for _ in range(feature_num)], encode='ordinal').fit(X_train)
        X_train_kbin = kbins.transform(X_train)
        X_test_kbin = kbins.transform(X_test)

        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)
        enc.fit(X_train_kbin)
        X_train_kbin = enc.transform(X_train_kbin)
        X_test_kbin = enc.transform(X_test_kbin)

        clf = LogisticRegression(random_state=random_state, solver='lbfgs')
        clf.fit(X_train_kbin, y_train)
        score_kbin = clf.score(X_test_kbin, y_test)
        print("KBins bucketing: %s" % score_kbin)
        kbin += score_kbin

        # 切分
        X_train_cut = feature_cut(X_train)
        X_test_cut = feature_cut(X_test)

        enc = OneHotEncoder(handle_unknown='ignore', sparse=False)
        enc.fit(X_train_cut)
        X_train_cut = enc.transform(X_train_cut)
        X_test_cut = enc.transform(X_test_cut)

        clf = LogisticRegression(random_state=random_state, solver='lbfgs')
        clf.fit(X_train_cut, y_train)
        score_cut = clf.score(X_test_cut, y_test)
        print("our bucketing: %s" % score_cut)
        cut += score_cut

    print(s/10)
    print(kbin/10)
    print(cut/10)
